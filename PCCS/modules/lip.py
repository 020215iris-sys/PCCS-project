import os
import csv
import requests
from datetime import datetime
from bs4 import BeautifulSoup


# ---------------------------------------------------
# 1. ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜
# ---------------------------------------------------
def download_image(url, save_path):
    try:
        img = requests.get(url, timeout=10)
        if img.status_code == 200:
            with open(save_path, "wb") as f:
                f.write(img.content)
            return True
    except:
        return False
    return False


# ---------------------------------------------------
# 2. HTML íŒŒì¼ì—ì„œ ì •ë³´ ì¶”ì¶œ
# ---------------------------------------------------
def parse_lip_html(html_path):
    with open(html_path, "r", encoding="utf-8") as f:
        html = f.read()

    soup = BeautifulSoup(html, "html.parser")

    # ë¸Œëœë“œëª…
    brand = "UnknownBrand"
    brand_tag = soup.select_one(".tx_brand, .prd_brand")
    if brand_tag:
        brand = brand_tag.get_text(strip=True)

    # ì œí’ˆëª…
    product_name = "UnknownProduct"
    name_tag = soup.select_one(".prd_name, .product_tit")
    if name_tag:
        product_name = name_tag.get_text(strip=True)

    # ì»¬ëŸ¬ì¹© ì´ë¯¸ì§€ë“¤.
    chip_imgs = soup.select(".ColorChips_colorchip-item__PXPll img")
    image_urls = [img["src"] for img in chip_imgs if img.get("src")]

    return brand, product_name, image_urls


# ---------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ (HTML â†’ ì´ë¯¸ì§€ ì €ì¥ + CSV ê¸°ë¡)
# ---------------------------------------------------
def run_from_html(html_path):
    BASE = os.path.dirname(os.path.dirname(__file__))  # /PCCS
    RESULT_DIR = os.path.join(BASE, "result")
    os.makedirs(RESULT_DIR, exist_ok=True)

    # ì´ë¯¸ì§€ ì €ì¥ í´ë”
    COLORCHIP_DIR = os.path.join(RESULT_DIR, "colorchips")
    os.makedirs(COLORCHIP_DIR, exist_ok=True)

    CSV_PATH = os.path.join(RESULT_DIR, "lip_info.csv")

    # HTML ë¶„ì„
    brand, product_name, image_urls = parse_lip_html(html_path)

    # ê³ ìœ ë²ˆí˜¸ = html íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
    product_id = os.path.splitext(os.path.basename(html_path))[0]

    rows = []

    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° íŒŒì¼ëª… ìƒì„±
    for idx, url in enumerate(image_urls, start=1):
        filename = f"{brand}_{product_name}_{product_id}_chip{idx}.jpg"
        filename = filename.replace("/", "_").replace(" ", "_")
        save_path = os.path.join(COLORCHIP_DIR, filename)

        download_image(url, save_path)

        rows.append({
            "brand": brand,
            "product_name": product_name,
            "product_id": product_id,
            "image_url": url,
            "saved_filename": filename,
            "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })

    # CSV ì €ì¥ (ì¤‘ë³µ í—¤ë” ë°©ì§€)
    header = ["brand", "product_name", "product_id", "image_url", "saved_filename", "crawled_at"]
    write_header = not os.path.exists(CSV_PATH)

    with open(CSV_PATH, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        if write_header:
            writer.writeheader()
        writer.writerows(rows)

    print(f"\nâœ” ë¸Œëœë“œ: {brand}")
    print(f"âœ” ì œí’ˆëª…: {product_name}")
    print(f"âœ” ì €ì¥ëœ ì»¬ëŸ¬ì¹© ì´ë¯¸ì§€ ìˆ˜: {len(image_urls)}")
    print(f"âœ” ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {COLORCHIP_DIR}")
    print(f"âœ” CSV ì €ì¥ ìœ„ì¹˜: {CSV_PATH}")
    print("ğŸ‰ ì™„ë£Œ!")


# ---------------------------------------------------
# 4. ì§ì ‘ ì‹¤í–‰í•  ë•Œ
# ---------------------------------------------------
if __name__ == "__main__":
    # ì˜ˆ: ë‚˜ì—°ì´ ì €ì¥í•œ HTML íŒŒì¼
    html_file = "lip_page.html"  # íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ì…ë ¥
    run_from_html(html_file)
