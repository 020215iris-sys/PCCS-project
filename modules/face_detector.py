import cv2
import numpy as np
from PIL import Image
import mediapipe as mp

mp_face = mp.solutions.face_detection
mp_face_mesh = mp.solutions.face_mesh

# Mediapipe ì´ˆê¸°í™”
face_detection = mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5
)


# -------------------------------------------------
# ì–¼êµ´ íƒì§€
# -------------------------------------------------
def detect_face(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {image_path}")

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    result = face_detection.process(img_rgb)

    if not result.detections:
        return img, None, None

    det = result.detections[0]
    bbox = det.location_data.relative_bounding_box

    h, w, _ = img.shape
    x1 = int(bbox.xmin * w)
    y1 = int(bbox.ymin * h)
    x2 = int((bbox.xmin + bbox.width) * w)
    y2 = int((bbox.ymin + bbox.height) * h)

    # ==========================================
    # ğŸ”¥ ì¶”ê°€ëœ ë¶€ë¶„: ì–¼êµ´ ë°•ìŠ¤ ì‹œê°í™” + ì €ì¥
    # ==========================================
    img_box = img.copy()
    cv2.rectangle(img_box, (x1, y1), (x2, y2), (0, 255, 255), 2)

    save_path = "face_box.png"
    cv2.imwrite(save_path, img_box)
    print(f"[ì €ì¥ë¨] ì–¼êµ´ ë°•ìŠ¤ ì´ë¯¸ì§€ â†’ {save_path}")
    # ==========================================

    # ì–¼êµ´ crop
    face_crop = img[y1:y2, x1:x2]

    return img, face_crop, (x1, y1, x2, y2)


# -------------------------------------------------
# ì…ìˆ  í•©ì„± í•¨ìˆ˜ (ì›ë³¸ mesh â†’ crop ë³€í™˜)
# -------------------------------------------------
def apply_lip_color(img, face_crop, bbox, lip_color=(255, 0, 0), alpha=0.6):
    x1, y1, x2, y2 = bbox

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(img_rgb)

    if not results.multi_face_landmarks:
        return face_crop

    landmarks = results.multi_face_landmarks[0].landmark

    # Mediapipe ì…ìˆ  ëœë“œë§ˆí¬
    lip_idx = list(range(61, 88)) + list(range(291, 318))

    # crop ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ë³€í™˜
    lip_points_crop = []
    h, w, _ = img.shape
    for idx in lip_idx:
        lx = int(landmarks[idx].x * w)
        ly = int(landmarks[idx].y * h)
        lip_points_crop.append((lx - x1, ly - y1))

    lip_points_crop = np.array(lip_points_crop)

    # ë§ˆìŠ¤í¬ ìƒì„±
    mask = np.zeros_like(face_crop, dtype=np.uint8)
    cv2.fillPoly(mask, [lip_points_crop.astype(np.int32)], (255, 255, 255))

    # ë¦½ ìƒ‰ìƒ (BGR)
    color_layer = np.zeros_like(face_crop)
    color_layer[:] = lip_color[::-1]

    # ìƒ‰ ì ìš©
    lip_colored = cv2.addWeighted(face_crop, 1-alpha, color_layer, alpha, 0)

    # ë§ˆìŠ¤í¬ë¡œ í•©ì„±
    output = face_crop.copy()
    output[mask[:, :, 0] > 0] = lip_colored[mask[:, :, 0] > 0]

    return output


# -------------------------------------------------
# before/after ì¶œë ¥
# -------------------------------------------------
def generate_before_after(image_path, lip_color=(255, 0, 128)):
    original_img, face_crop, bbox = detect_face(image_path)
    if face_crop is None:
        print("ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    lip_applied = apply_lip_color(original_img, face_crop, bbox, lip_color)

    # face_crop ì˜ì—­ì— ë®ì–´ì“°ê¸°
    x1, y1, x2, y2 = bbox
    after_img = original_img.copy()
    after_img[y1:y2, x1:x2] = lip_applied

    before = Image.fromarray(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))
    after = Image.fromarray(cv2.cvtColor(after_img, cv2.COLOR_BGR2RGB))

    combined = Image.new('RGB', (before.width*2, before.height))
    combined.paste(before, (0,0))
    combined.paste(after, (before.width, 0))

    combined.save("before_after_fixed.jpg")
    print("ì €ì¥ ì™„ë£Œ: before_after_fixed.jpg")


if __name__ == "__main__":
    generate_before_after("test.jpg", lip_color=(255, 0, 128))

import cv2
import mediapipe as mp

mp_face_mesh = mp.solutions.face_mesh

def visualize_facemesh(image_path, save_path="face_mesh_result.jpg"):
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError("ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    with mp_face_mesh.FaceMesh(
        static_image_mode=True,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5
    ) as mesh:

        result = mesh.process(img_rgb)

        if not result.multi_face_landmarks:
            print("FaceMesh ê°ì§€ ì‹¤íŒ¨")
            return None

        landmarks = result.multi_face_landmarks[0]
        h, w, _ = img.shape

        # ì–¼êµ´ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
        for lm in landmarks.landmark:
            x = int(lm.x * w)
            y = int(lm.y * h)
            cv2.circle(img, (x, y), 1, (0, 255, 0), -1)

        cv2.imwrite(save_path, img)
        print(f"FaceMesh ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ë¨ â†’ {save_path}")

        return save_path
